# Ссылки
[Quickstart](https://platform.openai.com/docs/quickstart?context=node)
[Токенайзер](https://platform.openai.com/tokenizer) перевод текста в предварительные токены 
[Playground](https://platform.openai.com/playground?mode=chat)- песочница для просмотра запросов и их ответов.
[API reference](https://platform.openai.com/docs/api-reference/introduction) - дока по API
# Модели

Модель | Описание
-------- | --------
[GPT-4 and GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)|Набор моделей, которые улучшают GPT-3.5 и могут понимать, а также генерировать естественный язык или код.
[GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5)| Набор моделей, которые улучшают GPT-3 и могут понимать, а также генерировать естественный язык или код.
[DALL·E](https://platform.openai.com/docs/models/dall-e)|Модель, которая может генерировать и редактировать изображения с помощью подсказки на естественном языке.
[TTS](https://platform.openai.com/docs/models/tts)|Набор моделей, которые могут преобразовывать текст в естественно звучащую речь.
[Whisper](https://platform.openai.com/docs/models/whisper)|Модель, которая может конвертировать аудио в текст
[Embeddings](https://platform.openai.com/docs/models/embeddings)|Набор моделей, способных преобразовывать текст в числовую форму.
[Moderation](https://platform.openai.com/docs/models/moderation)|Точно настроенная модель, которая может определить, является ли текст конфиденциальным или небезопасным.
[GPT base](https://platform.openai.com/docs/models/gpt-base)|Набор моделей без инструкций, которые могут понимать, а также генерировать естественный язык или код.
[GPT-3](https://platform.openai.com/docs/models/gpt-3)Legacy| Набор моделей, которые могут понимать и генерировать естественный язык.
[Deprecated](https://platform.openai.com/docs/deprecations)| Полный список моделей, которые устарели, а также предлагаемые замены.

## Модели для ресерчеров

Модель/API | Описание
-------- | --------
text-davinci-003|модель InstructGPT. Обучение с подкреплением с помощью моделей вознаграждения, обученных на основе сравнений, проведенных людьми.
gpt-3.5-turbo | Улучшение text-davinci-003 оптимизированная для чата
gpt-3.5-turbo-1106 | Обновленый GPT 3.5 Turbo Новейшая модель GPT-3.5 Turbo с улучшенным выполнением инструкций, режимом JSON, воспроизводимыми выходными данными, параллельным вызовом функций и многим другим. Возвращает максимум 4096 выходных токенов. Принимает в контекст 16,385 токенов



# Локальное разворачивание(curl нужно)
## Node.js
Создаёте пустой проект посредством **npm install node**
**npm install --save openai**
В _package.json_ добавляете "type": "module"
В файле js прописываете 
```js
import OpenAI from "openai";

  

const openai = new OpenAI({apiKey : 'YOUR_API_KEY'});

  

async function main() {

  const completion = await openai.chat.completions.create({

    messages: [{ role: "system", content: "You are a helpful assistant." }],

    model: "gpt-3.5-turbo",

  });

  

  console.log(completion.choices[0]);

}

  

main();
```
Запускаете посредством терминала **node openai_test.js** 
В ответ выдаст в терминале:
```js
{
  index: 0,
  message: { role: 'assistant', content: 'How may I assist you today?' },
  finish_reason: 'stop'
}
```


## [Curl](https://platform.openai.com/docs/quickstart?context=curl)
Проверка установки curl 
``` curl
curl https://platform.openai.com
```
### Установка своего ключа(позже)
### API запросы
```js
curl https://api.openai.com/v1/chat/completions   
-H "Content-Type: application/json"   
-H "Authorization: Bearer $OPENAI_API_KEY"   
-d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "system",
        "content": "You are a poetic assistant, skilled in explaining complex programming concepts with creative flair."
      },
      {
        "role": "user",
        "content": "Compose a poem that explains the concept of recursion in programming."
      }
    ]
  }'
```

# Работа с запросами и ответами
## [Assistants](https://platform.openai.com/docs/assistants/overview)BETA
### Создание ассистента
POST https://api.openai.com/v1/assistants
Можно создать своего ассистента, задать ему инструкции и модель, в которой он будет работать.
#### Request body
**model** 
	id модели.
**name**  
	имя ассистента.
**description** 
	описание ассистента max 512.
**instructions** 
	инструкции ассистента которые он использует max 32768.
**tools** 
	список инструментов, которые может использовать ассистент max 128.
**files_ids** 
	id файлов прикрепленных к ассистенту max 20. Файлы упорядочены по дате их создания в возрастающем порядке.
**metadata**
	Набор из 16 пар ключ-значение, которые могут быть присоединены к объекту. Это может быть полезно для хранения дополнительной информации об объекте в структурированном формате. Ключи могут быть длиной не более 64 символов, а значения могут быть длиной не более 512 символов.
### Получение ассистента
GET https://api.openai.com/v1/assistants/{assistant_id}
**assistant_id**
	id ассистента
## [Threads](https://platform.openai.com/docs/api-reference/threads)BETA
Представляет собой поток, содержащий сообщения. Можно создавать потоки, с которыми взаимодействуют ассистенты. Можно создавать, получать, модифицировать и удалять.


## [Messages](https://platform.openai.com/docs/api-reference/messages)BETA
Представляет сообщение, внутри Треда
### Объект
### Запросы
#### Создание
POST https://api.openai.com/v1/threads/{thread_id}/messages
thread_id - параметр пути
##### Request body
**role** required
	Роль сущности создающее сообщение, сейчас поддерживается только **user**
**content** required
	Содержание
**file_ids**
	id файлов, которое сообщение должно использовать max 10. Полезно для инструментов возврата и интерпретации кода.
**metadata**
####  Retrieve message
GET https://api.openai.com/v1/threads/{thread_id}/messages/{message_id}
**thread_id
message_id**
#### List messages(дополнить)
GET https://api.openai.com/v1/threads/{thread_id}/messages
thread_id 
Получает список сообщений Треда
## [Runs](https://platform.openai.com/docs/api-reference/runs)BETA (дополнить)
Представляет выполнение на потоке.
### Create run
POST https://api.openai.com/v1/threads/{thread_id}/runs
thread_id

#### Request body
**assistant_id**
	id ассистента
**model**
	id модели для запуска, если указано значение, то оно переопределит модель ассистента, если нет, то используется модель ассистента
**instructions**
	Переопределите стандартное системное сообщение помощника. Это полезно для изменения поведения в каждом отдельном запуске.
**tools**
	Переопределяет инструменты для запуска.
**metadata**

### Retrieve run
GET https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}

## [Chat](https://platform.openai.com/docs/api-reference/chat)(актуальное)
### Create chat completion
POST https://api.openai.com/v1/chat/completions
#### Request body
**messages** required
	список сообщений составляющих беседу. user message, system message, assistant message различаются лишь ролью. Tool message добавляется tool_call_id, инструмент на который данное сообщение отвечает.
**model** required
	только "gpt-3.5-turbo" и выше.
**requency_penalty** default 0
	Число между -2.0 и 2.0. Положительные значения штрафуют новые токены на основе их существующей частоты в тексте до этого момента, уменьшая вероятность модели повторить ту же самую строку дословно. [Подробнее](https://platform.openai.com/docs/guides/text-generation/parameter-details)
**logit_bias** map default null
	Принимает JSON-объект, который сопоставляет токены (указанные их идентификаторами в токенизаторе) со значением связанного смещения от -100 до 100. Математически, смещение добавляется к логитам, генерируемым моделью перед выбором. Точный эффект будет различаться в зависимости от модели, но значения между -1 и 1 должны уменьшать или увеличивать вероятность выбора; значения, такие как -100 или 100, должны приводить к запрету или исключительному выбору соответствующего токена.
**max_tokens**
**n** default 1
	Сколько вариантов завершения чата нужно сгенерировать для каждого входящего сообщения. Обратите внимание, что вы будете оплачивать в зависимости от количества сгенерированных токенов для всех вариантов. Установите значение n равным 1, чтобы минимизировать затраты.
**presence_penalty**
	Число между -2.0 и 2.0. Положительные значения наказывают новые токены в зависимости от того, появляются ли они в тексте до этого момента, увеличивая вероятность модели говорить о новых темах.
**response_format** text or json_object
	Важно: при использовании режима JSON вы также должны указать модели самостоятельно создавать JSON с помощью системного или пользовательского сообщения. Без этого модель может генерировать бесконечный поток пробелов, пока генерация не достигнет лимита токенов, что приведет к длительному и кажущемуся "застрявшему" запросу. Также обратите внимание, что содержимое сообщения может быть частично обрезано, если finish_reason="length", что указывает на то, что генерация превысила максимальное количество токенов или длину максимального контекста разговора.
**seed**
	Эта функция находится в бета-версии. Если указано, наша система будет прилагать максимальные усилия для детерминированной выборки, так что повторные запросы с одинаковым зерном и параметрами должны возвращать одинаковый результат. Детерминизм не гарантируется, и вы должны обращаться к параметру ответа system_fingerprint, чтобы отслеживать изменения в бэкэнде.
**stop** string/array/null
	До 4 последовательностей, где API прекратит генерацию дальнейших токенов.
**stream** boolean/null
	Если установлено, будут отправляться частичные дельты сообщений, как в ChatGPT. Токены будут отправляться в виде событий, содержащих только данные, по мере их доступности, и поток будет завершен сообщением data: [DONE]. 
**temperature** number/null
	"разброс" или же точность выборки, используйте значения между 0 и 2. Большие значения как 0.8 сделают выходные данные более случайными, меньшие как 0.2 сделают их более целенаправленными и детерминированными.
**top_p**
	альтернатива для температуры, выборка ядра. Модель учитывает результаты токенов с вероятной массой. Значит что 0.1 что учитываются только токены, составляющие верхние 10% вероятности массы. **ИСПОЛЬЗОВАТЬ ТОЛЬКО ОДНО ИЗ НИХ!**
**tools** пока бета, не стоит использовать
	Список инструментов, которые модель может вызывать. В настоящее время поддерживаются только функции в качестве инструментов. Используйте это, чтобы предоставить список функций, для которых модель может генерировать входные данные в формате JSON.
**tool_choise** относится к параметру выше
**user**
	Уникальный идентификатор. [Подробнее](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids)


## [Embeddings](https://platform.openai.com/docs/api-reference/embeddings)
Векторные представления
Получите векторное представление заданного входного значения, которое может быть легко использовано моделями и алгоритмами машинного обучения.


## [Completions (Большинство моделей, которые поддерживают устаревшую конечную точку завершения, будут отключены 4 января 2024 года.)](https://platform.openai.com/docs/api-reference/completions)
### Request body

```js
{
    model: "gpt-3.5-turbo-instruct",
    prompt: "Say this is a test.",
    max_tokens: 7,
    temperature: 0,
  }
```
* **model** *required* - модель нужная нам из [списка моделей онлайн](https://platform.openai.com/docs/api-reference/models/list) и [[#Модели]]
* **prompt** *required* - запрос в виде текста 
* **max_tokens** *default = 16* - ограничение на использование токенов
* **temperature** *default = 1* - 
	*"разброс" или же точность выборки, используйте значения между 0 и 2. Большие значения как 0.8 сделают выходные данные более случайными, меньшие как 0.2 сделают их более целенаправленными и детерминированными.
* **top_p**  *optional* -
	альтернатива для температуры, выборка ядра. Модель учитывает результаты токенов с вероятной массой. Значит что 0.1 что учитываются только токены, составляющие верхние 10% вероятности массы. **ИСПОЛЬЗОВАТЬ ТОЛЬКО ОДНО ИЗ НИХ!**
* **messages** *optional* - сообщения с параметрами *role* и *content* . Prompt то же самое, только сразу выдаёт роль *user*
* **seed** *optional* - 
	*Если указано,  система приложит все усилия для детерминированной выборки, чтобы повторные запросы с одним и тем же начальным числом и параметрами возвращали один и тот же результат. *Вроде можно создать как раз шаблонизирование с помощью этого* 
* **n** *optional defaults = 1*  - Количество вариантов завершения общения, которые необходимо сгенерировать для каждого входного сообщения.
*  **user** *optional* - 
	Уникальный идентификатор. Отправка идентификаторов конечных пользователей в запросах может быть полезным инструментом, помогающим OpenAI отслеживать и обнаруживать злоупотребления. Это позволяет OpenAI предоставлять вашей команде более действенную обратную связь в случае обнаружения каких-либо нарушений политики в вашем приложении.  
	Идентификаторы должны представлять собой строку, которая однозначно идентифицирует каждого пользователя. Мы рекомендуем хешировать их имя пользователя или адрес электронной почты, чтобы избежать отправки нам какой-либо идентифицирующей информации. Если вы предлагаете предварительный просмотр своего продукта пользователям, не вошедшим в систему, вместо этого вы можете отправить идентификатор сеанса.

