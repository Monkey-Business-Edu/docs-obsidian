## Модели

Модель | Описание
-------- | --------
[GPT-4 and GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)|Набор моделей, которые улучшают GPT-3.5 и могут понимать, а также генерировать естественный язык или код.
[GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5)| Набор моделей, которые улучшают GPT-3 и могут понимать, а также генерировать естественный язык или код.
[DALL·E](https://platform.openai.com/docs/models/dall-e)|Модель, которая может генерировать и редактировать изображения с помощью подсказки на естественном языке.
[TTS](https://platform.openai.com/docs/models/tts)|Набор моделей, которые могут преобразовывать текст в естественно звучащую речь.
[Whisper](https://platform.openai.com/docs/models/whisper)|Модель, которая может конвертировать аудио в текст
[Embeddings](https://platform.openai.com/docs/models/embeddings)|Набор моделей, способных преобразовывать текст в числовую форму.
[Moderation](https://platform.openai.com/docs/models/moderation)|Точно настроенная модель, которая может определить, является ли текст конфиденциальным или небезопасным.
[GPT base](https://platform.openai.com/docs/models/gpt-base)|Набор моделей без инструкций, которые могут понимать, а также генерировать естественный язык или код.
[GPT-3](https://platform.openai.com/docs/models/gpt-3)Legacy| Набор моделей, которые могут понимать и генерировать естественный язык.
[Deprecated](https://platform.openai.com/docs/deprecations)| Полный список моделей, которые устарели, а также предлагаемые замены.

## Модели для ресерчеров

Модель/API | Описание
-------- | --------
text-davinci-003|модель InstructGPT. Обучение с подкреплением с помощью моделей вознаграждения, обученных на основе сравнений, проведенных людьми.
gpt-3.5-turbo | Улучшение text-davinci-003 оптимизированная для чата
gpt-3.5-turbo-1106 | Обновленый GPT 3.5 Turbo Новейшая модель GPT-3.5 Turbo с улучшенным выполнением инструкций, режимом JSON, воспроизводимыми выходными данными, параллельным вызовом функций и многим другим. Возвращает максимум 4096 выходных токенов. Принимает в контекст 16,385 токенов

